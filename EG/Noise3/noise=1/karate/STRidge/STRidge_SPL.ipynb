{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2990296",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import *\n",
    "from random import shuffle\n",
    "import math\n",
    "import pandas as pd\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db9b6a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generate(M,P_PDG,W,N,K,Noise):\n",
    "    #W是原数据集,代表哪些代理之间有连接，即网络\n",
    "    #N是W的行数，即代理的个数\n",
    "    #代理人的博弈策略\n",
    "    player = zeros((M+1,N))\n",
    "    #原始博弈策略放在第一行，随机设置\n",
    "    for i in range(N):\n",
    "        if random.random()<=0.5:\n",
    "            player[0,i] = 1 #1代表合作\n",
    "        else:\n",
    "            player[0,i] = 0 #0代表不合作\n",
    "    #计算每个节点的收益\n",
    "    #M轮博弈\n",
    "    F = zeros((1,N))\n",
    "    G = zeros((M,N))\n",
    "    A = zeros((N,M,N))\n",
    "    for t in range(M):\n",
    "        for i in range(N):\n",
    "            if player[t,i] == 1:\n",
    "                s1 = array([[1],[0]])\n",
    "            else:\n",
    "                s1 = array([[0],[1]])\n",
    "            for j in range(N):\n",
    "                if player[t,j] == 0:\n",
    "                    s2 = array([[0],[1]])\n",
    "                else:\n",
    "                    s2 = array([[1],[0]])\n",
    "                F[0,j] = ((s1.T).dot(P_PDG)).dot(s2) #如果代理i和j连接，则代理i的收益为F[0,j]\n",
    "            A[i,t,:] = F  #A:N*M*N   \n",
    "            # F是三维矩阵A的第i页，第t行\n",
    "            G[t,i] = F.dot(W[:,i]) #第t轮代理i的收益\n",
    "        # update strategies\n",
    "        for k in range(N):\n",
    "            s=[i for i,x in enumerate(list(W[:,k])) if x>=1]     # 找出与代理k合作的代理的索引\n",
    "            if len(s)!=0: # 如果有代理与代理k合作\n",
    "                shuffle(s)\n",
    "                P = 1/(1+math.e**((G[t,k]-G[t,s[0]])/K)) # 费米规则\n",
    "                if random.random()<= P:\n",
    "                    player[t+1,k] = player[t,s[0]]\n",
    "                else:\n",
    "                    player[t+1,k] = player[t,k]\n",
    "            else: # 如果没有代理与代理k合作\n",
    "                player[t+1,k] = player[t,k]\n",
    "    # add noise for G\n",
    "    Aa = G + Noise*random.random((M,N)) # m轮收益总矩阵：包含每一轮的收益M*N\n",
    "    return [A,Aa]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f40594aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TrainSTRidge(R, Ut, lam, d_tol, maxit = 25, STR_iters = 10, l0_penalty = None, normalize = 2, split = 0.8, print_best_tol = False):\n",
    "    \"\"\"\n",
    "    This function trains a predictor using STRidge.\n",
    "\n",
    "    It runs over different values of tolerance and trains predictors on a training set, then evaluates them \n",
    "    using a loss function on a holdout set.\n",
    "\n",
    "    Please note published article has typo.  Loss function used here for model selection evaluates fidelity using 2-norm,\n",
    "    not squared 2-norm.\n",
    "    \"\"\"\n",
    "\n",
    "    # Split data into 80% training and 20% test, then search for the best tolderance.\n",
    "    np.random.seed(0) # for consistancy\n",
    "    n,_ = R.shape\n",
    "    train = np.random.choice(n, int(n*split), replace = False)\n",
    "    test = [i for i in np.arange(n) if i not in train]\n",
    "    TrainR = R[train,:]\n",
    "    TestR = R[test,:]\n",
    "    TrainY = Ut[train,:]\n",
    "    TestY = Ut[test,:]\n",
    "    D = TrainR.shape[1]       \n",
    "\n",
    "    # Set up the initial tolerance and l0 penalty\n",
    "    d_tol = float(d_tol)\n",
    "    tol = d_tol\n",
    "    if l0_penalty == None: l0_penalty = 0.001*np.linalg.cond(R)\n",
    "\n",
    "    # Get the standard least squares estimator\n",
    "    w = np.zeros((D,1))\n",
    "    w_best = np.linalg.lstsq(TrainR, TrainY)[0]\n",
    "    err_best = np.linalg.norm(TestY - TestR.dot(w_best), 2) + l0_penalty*np.count_nonzero(w_best)\n",
    "    tol_best = 0\n",
    "\n",
    "    # Now increase tolerance until test performance decreases\n",
    "    for iter in range(maxit):\n",
    "\n",
    "        # Get a set of coefficients and error\n",
    "        w = STRidge(R,Ut,lam,STR_iters,tol,normalize = normalize)\n",
    "        err = np.linalg.norm(TestY - TestR.dot(w), 2) + l0_penalty*np.count_nonzero(w)\n",
    "\n",
    "        # Has the accuracy improved?\n",
    "        if err <= err_best:\n",
    "            err_best = err\n",
    "            w_best = w\n",
    "            tol_best = tol\n",
    "            tol = tol + d_tol\n",
    "\n",
    "        else:\n",
    "            tol = max([0,tol - 2*d_tol])\n",
    "            d_tol  = 2*d_tol / (maxit - iter)\n",
    "            tol = tol + d_tol\n",
    "\n",
    "    if print_best_tol: \n",
    "        print (\"Optimal tolerance:\", tol_best)\n",
    "    return w_best\n",
    "\n",
    "def STRidge(X0, y, lam, maxit, tol, normalize = 2, print_results = False):\n",
    "    \"\"\"\n",
    "    Sequential Threshold Ridge Regression algorithm for finding (hopefully) sparse \n",
    "    approximation to X^{-1}y.  The idea is that this may do better with correlated observables.\n",
    "\n",
    "    This assumes y is only one column\n",
    "    \"\"\"\n",
    "\n",
    "    n,d = X0.shape\n",
    "    X = np.zeros((n,d), dtype=np.complex64)\n",
    "    # First normalize data\n",
    "    if normalize != 0:\n",
    "        Mreg = np.zeros((d,1))\n",
    "        for i in range(0,d):\n",
    "            Mreg[i] = 1.0/(np.linalg.norm(X0[:,i],normalize))\n",
    "            X[:,i] = Mreg[i]*X0[:,i]\n",
    "    else: X = X0\n",
    "    \n",
    "    # Get the standard ridge esitmate\n",
    "    if lam != 0: w = np.linalg.lstsq(X.T.dot(X) + lam*np.eye(d),X.T.dot(y))[0]\n",
    "    else: w = np.linalg.lstsq(X,y)[0]\n",
    "    num_relevant = d\n",
    "    biginds = np.where( abs(w) > tol)[0]\n",
    "    \n",
    "    # Threshold and continue\n",
    "    for j in range(maxit):\n",
    "\n",
    "        # Figure out which items to cut out\n",
    "        smallinds = np.where( abs(w) < tol)[0]\n",
    "        new_biginds = [i for i in range(d) if i not in smallinds]\n",
    "            \n",
    "        # If nothing changes then stop\n",
    "        if num_relevant == len(new_biginds): break\n",
    "        else: num_relevant = len(new_biginds)\n",
    "            \n",
    "        # Also make sure we didn't just lose all the coefficients\n",
    "        if len(new_biginds) == 0:\n",
    "            if j == 0: \n",
    "                #if print_results: print \"Tolerance too high - all coefficients set below tolerance\"\n",
    "                return w\n",
    "            else: break\n",
    "        biginds = new_biginds\n",
    "        \n",
    "        # Otherwise get a new guess\n",
    "        w[smallinds] = 0\n",
    "        if lam != 0: w[biginds] = np.linalg.lstsq(X[:, biginds].T.dot(X[:, biginds]) + lam*np.eye(len(biginds)),X[:, biginds].T.dot(y))[0]\n",
    "        else: w[biginds] = np.linalg.lstsq(X[:, biginds],y)[0]\n",
    "\n",
    "    # Now that we have the sparsity pattern, use standard least squares to get w\n",
    "    if biginds != []: w[biginds] = np.linalg.lstsq(X[:, biginds],y)[0]\n",
    "    \n",
    "    if normalize != 0: return np.multiply(Mreg,w)\n",
    "    else: return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9fe2e4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "M = 10 #m轮更新\n",
    "b = 1.2 #叛逃者的收益\n",
    "K = 0.1\n",
    "P_PDG = array([[1,0],[b,0]]) #2*2的收益矩阵\n",
    "Noise = 1\n",
    "W = np.loadtxt(\"karate.txt\") \n",
    "T = W.shape[0] #全部社区内个体的总数量\n",
    "SV = 6\n",
    "# the part for generate EG data\n",
    "y = zeros((SV*M,T))\n",
    "AA = zeros((T,SV*M,T))\n",
    "for i in range(SV): #产生6组A和Y的值\n",
    "    [A, Aa] = data_generate(M,P_PDG,W,T,K,Noise)\n",
    "    for j in range(M):\n",
    "        y[i*M+j,:] =Aa[j,:]\n",
    "        for k in range(T):\n",
    "            AA[k,i*M+j,:] = A[k,j,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf2aa481",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-13ac3e2d7f51>:30: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  w_best = np.linalg.lstsq(TrainR, TrainY)[0]\n",
      "<ipython-input-3-13ac3e2d7f51>:76: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  if lam != 0: w = np.linalg.lstsq(X.T.dot(X) + lam*np.eye(d),X.T.dot(y))[0]\n",
      "<ipython-input-3-13ac3e2d7f51>:102: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  if lam != 0: w[biginds] = np.linalg.lstsq(X[:, biginds].T.dot(X[:, biginds]) + lam*np.eye(len(biginds)),X[:, biginds].T.dot(y))[0]\n",
      "<ipython-input-3-13ac3e2d7f51>:106: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  if biginds != []: w[biginds] = np.linalg.lstsq(X[:, biginds],y)[0]\n",
      "<ipython-input-8-0ca45682905e>:5: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  X[i,j]=w[i,0]\n",
      "<ipython-input-3-13ac3e2d7f51>:106: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  if biginds != []: w[biginds] = np.linalg.lstsq(X[:, biginds],y)[0]\n"
     ]
    }
   ],
   "source": [
    "X=zeros((T,T))\n",
    "for j in range(T):\n",
    "    w = TrainSTRidge(AA[j], y[:,j].reshape(-1,1),10**-1,1)\n",
    "    for i in range(w.shape[0]):\n",
    "        X[i,j]=w[i,0]\n",
    "np.savetxt(\"X.txt\", X,fmt='%f',delimiter=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "40b38b8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.24141008e-01 1.49674867e-01 2.22321388e-01 3.86488981e-01\n",
      "  9.02598476e-01 4.49949990e-01 6.13063458e-01 9.02348583e-01\n",
      "  9.92803504e-02 9.69809068e-01 6.53140036e-01 1.70909585e-01\n",
      "  3.58152167e-01 7.50686141e-01 6.07830669e-01 3.25047229e-01\n",
      "  3.84254265e-02 6.34274058e-01 9.58949269e-01 6.52790317e-01\n",
      "  6.35058874e-01 9.95299568e-01 5.81850329e-01 4.14368588e-01\n",
      "  4.74697502e-01 6.23510101e-01 3.38007615e-01 6.74752322e-01\n",
      "  3.17201742e-01 7.78345482e-01 9.49571053e-01 6.62526867e-01\n",
      "  1.35716356e-02 6.22846096e-01]\n",
      " [6.73659631e-01 9.71945002e-01 8.78193471e-01 5.09624377e-01\n",
      "  5.57146937e-02 4.51159215e-01 1.99876654e-02 4.41710921e-01\n",
      "  9.79586729e-01 3.59444464e-01 4.80893531e-01 6.88661183e-01\n",
      "  8.80475889e-01 9.18235466e-01 2.16822138e-01 5.65188867e-01\n",
      "  8.65102561e-01 5.08968961e-01 9.16722954e-01 9.21157610e-01\n",
      "  8.31124926e-02 2.77718561e-01 9.35670486e-03 8.42342080e-01\n",
      "  6.47174140e-01 8.41386119e-01 2.64730164e-01 3.97820753e-01\n",
      "  5.52821480e-01 1.64940460e-01 3.69808093e-01 1.46441763e-01\n",
      "  5.69618406e-01 7.03737279e-01]\n",
      " [2.88476437e-01 4.33288062e-01 7.56106694e-01 3.96098275e-01\n",
      "  8.96038388e-01 6.38921076e-01 8.91554437e-01 6.80055569e-01\n",
      "  4.49197738e-01 9.78570928e-01 1.16201910e-01 7.67023704e-01\n",
      "  4.11820139e-01 6.75439081e-01 2.49796276e-01 3.13218332e-01\n",
      "  9.65416221e-01 5.88465085e-01 6.59668412e-01 5.33206254e-01\n",
      "  2.30533024e-01 3.94869293e-01 6.18808565e-01 4.74867515e-01\n",
      "  4.70132189e-01 7.16074531e-01 2.87991004e-01 3.83462225e-01\n",
      "  7.49169837e-01 8.78452190e-01 1.02863359e-01 9.23738895e-02\n",
      "  3.54046662e-01 5.51816259e-01]\n",
      " [3.36250935e-02 9.68961765e-01 3.20997241e-01 2.21262685e-01\n",
      "  1.41263905e-01 9.72599271e-02 9.84042241e-01 2.60340928e-01\n",
      "  5.37022521e-01 4.47926172e-01 9.95690891e-02 3.52311661e-01\n",
      "  4.69249174e-01 8.41140130e-01 9.04647744e-01 3.75593838e-02\n",
      "  5.08315449e-01 1.66847513e-01 7.79051020e-01 8.64933296e-01\n",
      "  4.11396724e-01 1.39972585e-01 3.32223853e-02 9.82574960e-01\n",
      "  3.73290751e-01 4.20075370e-01 5.05881151e-02 3.65496106e-01\n",
      "  1.66279737e-02 2.30742335e-01 7.64911699e-01 9.44123519e-01\n",
      "  7.49999249e-01 3.39403819e-01]\n",
      " [4.89548937e-01 3.38985117e-01 1.79490261e-01 1.70986599e-01\n",
      "  4.63450977e-01 8.74572958e-01 9.44119751e-01 6.08252866e-01\n",
      "  5.96655406e-01 7.83644245e-01 5.00026298e-01 5.03700568e-02\n",
      "  6.99098075e-01 9.92396399e-01 2.67262538e-01 6.79090616e-01\n",
      "  8.64281443e-01 7.50844246e-01 9.64489768e-01 5.54242435e-01\n",
      "  2.12390499e-01 2.22443224e-01 2.18749374e-01 5.69573535e-01\n",
      "  4.52109035e-01 9.70236683e-01 6.80544691e-01 8.52955659e-02\n",
      "  5.64183327e-02 4.87837704e-01 8.81004562e-01 9.76404387e-01\n",
      "  6.17657916e-01 5.42498775e-01]\n",
      " [8.54613580e-01 7.43834545e-01 4.78596326e-01 6.77081574e-01\n",
      "  6.07045061e-01 7.14696936e-01 4.69497183e-01 4.56014623e-01\n",
      "  9.06418087e-01 1.37220420e-01 2.29219323e-01 8.81585399e-01\n",
      "  9.04424976e-01 6.45784599e-01 3.24682972e-01 5.19711194e-01\n",
      "  5.53568650e-05 3.11860221e-01 4.25451538e-01 8.85337660e-01\n",
      "  6.79879456e-01 4.56129772e-01 4.83408617e-01 7.88739428e-01\n",
      "  2.29441834e-01 8.80297603e-01 3.13692393e-01 9.57450856e-01\n",
      "  4.71751571e-01 7.11583817e-01 1.53694305e-01 7.30442177e-01\n",
      "  6.46264437e-01 2.14880737e-01]\n",
      " [1.86458219e-01 8.07580269e-01 7.47079470e-01 6.74847346e-01\n",
      "  2.76893751e-01 1.74908874e-01 7.04474258e-01 4.63150200e-01\n",
      "  8.40428533e-01 2.04865762e-01 1.64958868e-01 1.24833057e-01\n",
      "  7.22080662e-01 3.04529649e-02 7.46994240e-01 9.25961651e-02\n",
      "  2.17450493e-01 7.49254417e-01 7.31693756e-01 4.56146372e-02\n",
      "  2.09157029e-01 2.86915043e-01 6.77263305e-01 6.30382897e-02\n",
      "  5.55649243e-01 9.24007349e-03 8.33038098e-01 9.84329434e-01\n",
      "  7.03494784e-01 1.81631200e-01 5.12393463e-01 5.80447137e-01\n",
      "  7.87542156e-01 6.06475460e-01]\n",
      " [2.18402855e-01 4.55168815e-01 8.78869742e-01 4.92268242e-01\n",
      "  7.15561157e-01 4.86159560e-01 7.08548150e-01 4.98140226e-01\n",
      "  8.44550079e-01 1.94342223e-01 7.73326010e-01 9.74258664e-01\n",
      "  8.62309777e-01 7.80426651e-01 9.85032279e-01 7.53569607e-01\n",
      "  4.04810637e-03 2.69479434e-01 4.10492138e-01 4.28223832e-01\n",
      "  2.97841819e-01 4.01132342e-01 1.20656991e-01 9.80699674e-01\n",
      "  4.06120493e-01 5.69210760e-01 3.43605503e-01 7.88872778e-01\n",
      "  4.11372414e-01 3.59271417e-01 3.99498910e-01 3.01830876e-01\n",
      "  7.75219777e-01 9.26212930e-01]\n",
      " [3.25310305e-01 9.52870672e-01 1.39483959e-02 5.33465682e-01\n",
      "  3.04582031e-01 8.82859998e-01 2.50622720e-01 6.77411829e-01\n",
      "  8.10424091e-01 4.32148050e-01 7.52134521e-01 8.29602248e-01\n",
      "  3.79033772e-01 9.65496098e-02 2.56139577e-01 5.91935158e-01\n",
      "  4.76477201e-01 4.87934569e-01 4.58514552e-01 5.24592621e-01\n",
      "  4.42015318e-01 8.52634924e-01 4.33438974e-01 8.26870368e-01\n",
      "  5.09342065e-01 8.63769804e-02 6.60039862e-01 2.06594607e-01\n",
      "  8.47275323e-01 6.81359129e-01 1.78367349e-01 6.98590173e-02\n",
      "  9.68817080e-03 8.92049658e-01]\n",
      " [1.33465210e-01 7.79191974e-01 9.25163426e-01 7.15178749e-01\n",
      "  4.90818613e-01 4.69498303e-01 8.82709289e-01 4.88410060e-01\n",
      "  4.14567485e-01 1.74111952e-01 4.75289442e-01 7.83647965e-01\n",
      "  5.56429427e-01 1.59867082e-01 1.43829366e-01 6.49463030e-01\n",
      "  5.39223597e-01 3.25684766e-01 1.47013895e-01 1.59870067e-01\n",
      "  1.29412337e-01 5.78922388e-01 9.22601704e-02 9.10544722e-01\n",
      "  8.29717477e-02 8.00378462e-01 8.77130966e-01 9.34594564e-02\n",
      "  4.26305880e-01 4.73220674e-01 5.80197106e-01 7.16244174e-01\n",
      "  2.70689848e-02 7.31397340e-01]]\n"
     ]
    }
   ],
   "source": [
    "print(Noise*random.random((M,T)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b210bd53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TrainSTRidge_SPL(R, Ut, v, lam, d_tol, maxit = 25, STR_iters = 10, l0_penalty = None, normalize = 2, split = 0.8, print_best_tol = False):\n",
    "    \"\"\"\n",
    "    This function trains a predictor using STRidge_SPL.\n",
    "\n",
    "    It runs over different values of tolerance and trains predictors on a training set, then evaluates them \n",
    "    using a loss function on a holdout set.\n",
    "\n",
    "    Please note published article has typo.  Loss function used here for model selection evaluates fidelity using 2-norm,\n",
    "    not squared 2-norm.\n",
    "    \"\"\"\n",
    "\n",
    "    # Split data into 80% training and 20% test, then search for the best tolderance.\n",
    "    np.random.seed(0) # for consistancy\n",
    "    n,_ = R.shape\n",
    "    train = np.random.choice(n, int(n*split), replace = False)\n",
    "    test = [i for i in np.arange(n) if i not in train]\n",
    "    TrainR = R[train,:]\n",
    "    TestR = R[test,:]\n",
    "    TrainY = Ut[train,:]\n",
    "    TestY = Ut[test,:]\n",
    "    D = TrainR.shape[1]       \n",
    "\n",
    "    # Set up the initial tolerance and l0 penalty\n",
    "    d_tol = float(d_tol)\n",
    "    tol = d_tol\n",
    "    if l0_penalty == None: l0_penalty = 0.001*np.linalg.cond(R)\n",
    "\n",
    "    # Get the standard least squares estimator\n",
    "    w = np.zeros((D,1))\n",
    "    w_best = np.linalg.lstsq(TrainR, TrainY)[0]\n",
    "    err_best = np.linalg.norm(TestY - TestR.dot(w_best), 2) + l0_penalty*np.count_nonzero(w_best)\n",
    "    tol_best = 0\n",
    "\n",
    "    # Now increase tolerance until test performance decreases\n",
    "    for iter in range(maxit):\n",
    "\n",
    "        # Get a set of coefficients and error\n",
    "        w = STRidge_SPL(R,Ut,v,lam,STR_iters,tol,normalize = normalize)\n",
    "        err = np.linalg.norm(TestY - TestR.dot(w), 2) + l0_penalty*np.count_nonzero(w)\n",
    "\n",
    "        # Has the accuracy improved?\n",
    "        if err <= err_best:\n",
    "            err_best = err\n",
    "            w_best = w\n",
    "            tol_best = tol\n",
    "            tol = tol + d_tol\n",
    "\n",
    "        else:\n",
    "            tol = max([0,tol - 2*d_tol])\n",
    "            d_tol  = 2*d_tol / (maxit - iter)\n",
    "            tol = tol + d_tol\n",
    "\n",
    "    if print_best_tol: \n",
    "        print (\"Optimal tolerance:\", tol_best)\n",
    "    return w_best\n",
    "\n",
    "def STRidge_SPL(X0, y, v, lam, maxit, tol, normalize = 2, print_results = False):\n",
    "    \"\"\"\n",
    "    Sequential Threshold Ridge Regression algorithm for finding (hopefully) sparse \n",
    "    approximation to X^{-1}y.  The idea is that this may do better with correlated observables.\n",
    "\n",
    "    This assumes y is only one column\n",
    "    \"\"\"\n",
    "\n",
    "    n,d = X0.shape\n",
    "    X = np.zeros((n,d), dtype=np.complex64)\n",
    "    # First normalize data\n",
    "    if normalize != 0:\n",
    "        Mreg = np.zeros((d,1))\n",
    "        for i in range(0,d):\n",
    "            Mreg[i] = 1.0/(np.linalg.norm(X0[:,i],normalize))\n",
    "            X[:,i] = Mreg[i]*X0[:,i]\n",
    "    else: X = X0\n",
    "    \n",
    "    # Get the standard ridge esitmate\n",
    "    if lam != 0: w = np.linalg.lstsq(X.T.dot(X*v) + lam*np.eye(d),X.T.dot(y*v))[0]\n",
    "    else: w = np.linalg.lstsq(X*v,y*v)[0]\n",
    "    num_relevant = d\n",
    "    biginds = np.where( abs(w) > tol)[0]\n",
    "    \n",
    "    # Threshold and continue\n",
    "    for j in range(maxit):\n",
    "\n",
    "        # Figure out which items to cut out\n",
    "        smallinds = np.where( abs(w) < tol)[0]\n",
    "        new_biginds = [i for i in range(d) if i not in smallinds]\n",
    "            \n",
    "        # If nothing changes then stop\n",
    "        if num_relevant == len(new_biginds): break\n",
    "        else: num_relevant = len(new_biginds)\n",
    "            \n",
    "        # Also make sure we didn't just lose all the coefficients\n",
    "        if len(new_biginds) == 0:\n",
    "            if j == 0: \n",
    "                #if print_results: print \"Tolerance too high - all coefficients set below tolerance\"\n",
    "                return w\n",
    "            else: break\n",
    "        biginds = new_biginds\n",
    "        \n",
    "        # Otherwise get a new guess\n",
    "        w[smallinds] = 0\n",
    "        if lam != 0: w[biginds] = np.linalg.lstsq(X[:, biginds].T.dot(X[:, biginds]*v) + lam*np.eye(len(biginds)),X[:, biginds].T.dot(y*v))[0]\n",
    "        else: w[biginds] = np.linalg.lstsq(X[:, biginds]*v,y*v)[0]\n",
    "\n",
    "    # Now that we have the sparsity pattern, use standard least squares to get w\n",
    "    if biginds != []: w[biginds] = np.linalg.lstsq(X[:, biginds]*v,y*v)[0]\n",
    "    \n",
    "    if normalize != 0: return np.multiply(Mreg,w)\n",
    "    else: return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c4d6f9bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-5e04d6e95ebc>:30: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  w_best = np.linalg.lstsq(TrainR, TrainY)[0]\n",
      "<ipython-input-10-5e04d6e95ebc>:76: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  if lam != 0: w = np.linalg.lstsq(X.T.dot(X*v) + lam*np.eye(d),X.T.dot(y*v))[0]\n",
      "<ipython-input-10-5e04d6e95ebc>:102: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  if lam != 0: w[biginds] = np.linalg.lstsq(X[:, biginds].T.dot(X[:, biginds]*v) + lam*np.eye(len(biginds)),X[:, biginds].T.dot(y*v))[0]\n",
      "<ipython-input-10-5e04d6e95ebc>:106: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  if biginds != []: w[biginds] = np.linalg.lstsq(X[:, biginds]*v,y*v)[0]\n",
      "<ipython-input-28-30eda53c4b62>:18: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  X[i,j]=w[i,0]\n",
      "<ipython-input-10-5e04d6e95ebc>:106: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  if biginds != []: w[biginds] = np.linalg.lstsq(X[:, biginds]*v,y*v)[0]\n"
     ]
    }
   ],
   "source": [
    "X=zeros((T,T))\n",
    "v = ones((SV*M,1))\n",
    "v1 = zeros((SV*M,1))\n",
    "Los = zeros((SV*M,T))\n",
    "losss = zeros((SV*M,1))\n",
    "lambda_0=0.3\n",
    "t=0\n",
    "while (t<13):  \n",
    "    if (v==v1).all():\n",
    "        break\n",
    "    else:\n",
    "        for j in range(T):\n",
    "            w = TrainSTRidge_SPL(AA[j], y[:,j].reshape(-1,1), v,10**-1,1)\n",
    "            Lo =  abs((np.dot(AA[j], w))-y[:,j].reshape(-1,1))\n",
    "            for i in range(SV*M):\n",
    "                Los[i,j]=Lo[i]\n",
    "            for i in range(w.shape[0]):\n",
    "                X[i,j]=w[i,0]\n",
    "        for i in range(SV*M):\n",
    "            losss[i]=np.mean(Los[i,:])\n",
    "        t = t+1\n",
    "        for i in range(SV*M):\n",
    "            if losss[i]<lambda_0:\n",
    "                v[i]=1-losss[i]/lambda_0\n",
    "            else:\n",
    "                v[i]=0\n",
    "        lambda_0 = lambda_0*1.25\n",
    "        #lambda_0 = lambda_0 + np.mean(losss)      \n",
    "np.savetxt(\"X1.txt\", X,fmt='%f',delimiter=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ff62e5d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9208732 ],\n",
       "       [0.92813227],\n",
       "       [0.9265653 ],\n",
       "       [0.93767183],\n",
       "       [0.93002006],\n",
       "       [0.92408387],\n",
       "       [0.91734411],\n",
       "       [0.93588241],\n",
       "       [0.93056869],\n",
       "       [0.93276318],\n",
       "       [0.91655288],\n",
       "       [0.92866714],\n",
       "       [0.92562782],\n",
       "       [0.93707048],\n",
       "       [0.93091641],\n",
       "       [0.91366097],\n",
       "       [0.9336348 ],\n",
       "       [0.9268876 ],\n",
       "       [0.92965922],\n",
       "       [0.93620847],\n",
       "       [0.92261815],\n",
       "       [0.91374636],\n",
       "       [0.88144799],\n",
       "       [0.89414322],\n",
       "       [0.8894914 ],\n",
       "       [0.88044605],\n",
       "       [0.89239073],\n",
       "       [0.86488646],\n",
       "       [0.89992771],\n",
       "       [0.88738778],\n",
       "       [0.90038967],\n",
       "       [0.89722606],\n",
       "       [0.90149313],\n",
       "       [0.89921199],\n",
       "       [0.8768321 ],\n",
       "       [0.88489861],\n",
       "       [0.89509714],\n",
       "       [0.88476705],\n",
       "       [0.88965238],\n",
       "       [0.90161287],\n",
       "       [0.9341564 ],\n",
       "       [0.94174511],\n",
       "       [0.947561  ],\n",
       "       [0.94707064],\n",
       "       [0.93615883],\n",
       "       [0.93002439],\n",
       "       [0.92934234],\n",
       "       [0.94270749],\n",
       "       [0.93744322],\n",
       "       [0.93857451],\n",
       "       [0.94221616],\n",
       "       [0.92390063],\n",
       "       [0.91357717],\n",
       "       [0.92427183],\n",
       "       [0.92739644],\n",
       "       [0.92419395],\n",
       "       [0.91340827],\n",
       "       [0.92714312],\n",
       "       [0.92961498],\n",
       "       [0.92737396]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e00da151",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-5e04d6e95ebc>:30: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  w_best = np.linalg.lstsq(TrainR, TrainY)[0]\n",
      "<ipython-input-10-5e04d6e95ebc>:76: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  if lam != 0: w = np.linalg.lstsq(X.T.dot(X*v) + lam*np.eye(d),X.T.dot(y*v))[0]\n",
      "<ipython-input-10-5e04d6e95ebc>:102: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  if lam != 0: w[biginds] = np.linalg.lstsq(X[:, biginds].T.dot(X[:, biginds]*v) + lam*np.eye(len(biginds)),X[:, biginds].T.dot(y*v))[0]\n",
      "<ipython-input-10-5e04d6e95ebc>:106: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  if biginds != []: w[biginds] = np.linalg.lstsq(X[:, biginds]*v,y*v)[0]\n",
      "<ipython-input-44-2b475c1909a6>:17: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  X[i,j]=w[i,0]\n",
      "<ipython-input-10-5e04d6e95ebc>:106: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  if biginds != []: w[biginds] = np.linalg.lstsq(X[:, biginds]*v,y*v)[0]\n"
     ]
    }
   ],
   "source": [
    "X=zeros((T,T))\n",
    "v = ones((SV*M,T))\n",
    "v1 = zeros((SV*M,T))\n",
    "Los = zeros((SV*M,T))\n",
    "lambda_0=0.3\n",
    "t=0\n",
    "while (t<13):\n",
    "    if (v==v1).all():\n",
    "        break\n",
    "    else:\n",
    "        for j in range(T):\n",
    "            w = TrainSTRidge_SPL(AA[j], y[:,j].reshape(-1,1), v[:,j].reshape(-1,1),10**-1,1)\n",
    "            Lo =  abs((np.dot(AA[j], w))-y[:,j].reshape(-1,1))\n",
    "            for i in range(SV*M):\n",
    "                Los[i,j]=Lo[i]\n",
    "            for i in range(w.shape[0]):\n",
    "                X[i,j]=w[i,0]\n",
    "        t = t+1\n",
    "        for j in range(T):\n",
    "            for i in range(SV*M):\n",
    "                if Los[i,j]<lambda_0:\n",
    "                    v[i,j]=1-Los[i,j]/lambda_0\n",
    "                else:\n",
    "                    v[i,j]=0\n",
    "        #lambda_0 = lambda_0*1.05\n",
    "        lambda_0 = lambda_0 + np.mean(Los)\n",
    "np.savetxt(\"X2.txt\", X,fmt='%f',delimiter=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "15d2e7c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.87105127, 0.85327571, 0.9561944 , ..., 0.97500396, 0.96679882,\n",
       "        0.97161924],\n",
       "       [0.95537657, 0.99194657, 0.99095378, ..., 0.96916508, 0.8972592 ,\n",
       "        0.92429672],\n",
       "       [0.94641828, 0.91390407, 0.99705801, ..., 0.99156318, 0.90389361,\n",
       "        0.97105955],\n",
       "       ...,\n",
       "       [0.63535484, 0.9419794 , 0.97166635, ..., 0.93522197, 0.93033063,\n",
       "        0.95050489],\n",
       "       [0.89458023, 0.92616494, 0.98811372, ..., 0.93303618, 0.98417221,\n",
       "        0.9852479 ],\n",
       "       [0.94819044, 0.93486808, 0.93273317, ..., 0.87977302, 0.92362387,\n",
       "        0.95843202]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18984880",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2990296",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import *\n",
    "from random import shuffle\n",
    "import math\n",
    "import pandas as pd\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db9b6a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generate(M,P_PDG,W,N,K,Noise):\n",
    "    #W是原数据集,代表哪些代理之间有连接，即网络\n",
    "    #N是W的行数，即代理的个数\n",
    "    #代理人的博弈策略\n",
    "    player = zeros((M+1,N))\n",
    "    #原始博弈策略放在第一行，随机设置\n",
    "    for i in range(N):\n",
    "        if random.random()<=0.5:\n",
    "            player[0,i] = 1 #1代表合作\n",
    "        else:\n",
    "            player[0,i] = 0 #0代表不合作\n",
    "    #计算每个节点的收益\n",
    "    #M轮博弈\n",
    "    F = zeros((1,N))\n",
    "    G = zeros((M,N))\n",
    "    A = zeros((N,M,N))\n",
    "    for t in range(M):\n",
    "        for i in range(N):\n",
    "            if player[t,i] == 1:\n",
    "                s1 = array([[1],[0]])\n",
    "            else:\n",
    "                s1 = array([[0],[1]])\n",
    "            for j in range(N):\n",
    "                if player[t,j] == 0:\n",
    "                    s2 = array([[0],[1]])\n",
    "                else:\n",
    "                    s2 = array([[1],[0]])\n",
    "                F[0,j] = ((s1.T).dot(P_PDG)).dot(s2) #如果代理i和j连接，则代理i的收益为F[0,j]\n",
    "            A[i,t,:] = F  #A:N*M*N   \n",
    "            # F是三维矩阵A的第i页，第t行\n",
    "            G[t,i] = F.dot(W[:,i]) #第t轮代理i的收益\n",
    "        # update strategies\n",
    "        for k in range(N):\n",
    "            s=[i for i,x in enumerate(list(W[:,k])) if x>=1]     # 找出与代理k合作的代理的索引\n",
    "            if len(s)!=0: # 如果有代理与代理k合作\n",
    "                shuffle(s)\n",
    "                P = 1/(1+math.e**((G[t,k]-G[t,s[0]])/K)) # 费米规则\n",
    "                if random.random()<= P:\n",
    "                    player[t+1,k] = player[t,s[0]]\n",
    "                else:\n",
    "                    player[t+1,k] = player[t,k]\n",
    "            else: # 如果没有代理与代理k合作\n",
    "                player[t+1,k] = player[t,k]\n",
    "    # add noise for G\n",
    "    Aa = G + Noise*random.random((M,N)) # m轮收益总矩阵：包含每一轮的收益M*N\n",
    "    return [A,Aa]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f40594aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TrainSTRidge(R, Ut, lam, d_tol, maxit = 25, STR_iters = 10, l0_penalty = None, normalize = 2, split = 0.8, print_best_tol = False):\n",
    "    \"\"\"\n",
    "    This function trains a predictor using STRidge.\n",
    "\n",
    "    It runs over different values of tolerance and trains predictors on a training set, then evaluates them \n",
    "    using a loss function on a holdout set.\n",
    "\n",
    "    Please note published article has typo.  Loss function used here for model selection evaluates fidelity using 2-norm,\n",
    "    not squared 2-norm.\n",
    "    \"\"\"\n",
    "\n",
    "    # Split data into 80% training and 20% test, then search for the best tolderance.\n",
    "    np.random.seed(0) # for consistancy\n",
    "    n,_ = R.shape\n",
    "    train = np.random.choice(n, int(n*split), replace = False)\n",
    "    test = [i for i in np.arange(n) if i not in train]\n",
    "    TrainR = R[train,:]\n",
    "    TestR = R[test,:]\n",
    "    TrainY = Ut[train,:]\n",
    "    TestY = Ut[test,:]\n",
    "    D = TrainR.shape[1]       \n",
    "\n",
    "    # Set up the initial tolerance and l0 penalty\n",
    "    d_tol = float(d_tol)\n",
    "    tol = d_tol\n",
    "    if l0_penalty == None: l0_penalty = 0.001*np.linalg.cond(R)\n",
    "\n",
    "    # Get the standard least squares estimator\n",
    "    w = np.zeros((D,1))\n",
    "    w_best = np.linalg.lstsq(TrainR, TrainY)[0]\n",
    "    err_best = np.linalg.norm(TestY - TestR.dot(w_best), 2) + l0_penalty*np.count_nonzero(w_best)\n",
    "    tol_best = 0\n",
    "\n",
    "    # Now increase tolerance until test performance decreases\n",
    "    for iter in range(maxit):\n",
    "\n",
    "        # Get a set of coefficients and error\n",
    "        w = STRidge(R,Ut,lam,STR_iters,tol,normalize = normalize)\n",
    "        err = np.linalg.norm(TestY - TestR.dot(w), 2) + l0_penalty*np.count_nonzero(w)\n",
    "\n",
    "        # Has the accuracy improved?\n",
    "        if err <= err_best:\n",
    "            err_best = err\n",
    "            w_best = w\n",
    "            tol_best = tol\n",
    "            tol = tol + d_tol\n",
    "\n",
    "        else:\n",
    "            tol = max([0,tol - 2*d_tol])\n",
    "            d_tol  = 2*d_tol / (maxit - iter)\n",
    "            tol = tol + d_tol\n",
    "\n",
    "    if print_best_tol: \n",
    "        print (\"Optimal tolerance:\", tol_best)\n",
    "    return w_best\n",
    "\n",
    "def STRidge(X0, y, lam, maxit, tol, normalize = 2, print_results = False):\n",
    "    \"\"\"\n",
    "    Sequential Threshold Ridge Regression algorithm for finding (hopefully) sparse \n",
    "    approximation to X^{-1}y.  The idea is that this may do better with correlated observables.\n",
    "\n",
    "    This assumes y is only one column\n",
    "    \"\"\"\n",
    "\n",
    "    n,d = X0.shape\n",
    "    X = np.zeros((n,d), dtype=np.complex64)\n",
    "    # First normalize data\n",
    "    if normalize != 0:\n",
    "        Mreg = np.zeros((d,1))\n",
    "        for i in range(0,d):\n",
    "            Mreg[i] = 1.0/(np.linalg.norm(X0[:,i],normalize))\n",
    "            X[:,i] = Mreg[i]*X0[:,i]\n",
    "    else: X = X0\n",
    "    \n",
    "    # Get the standard ridge esitmate\n",
    "    if lam != 0: w = np.linalg.lstsq(X.T.dot(X) + lam*np.eye(d),X.T.dot(y))[0]\n",
    "    else: w = np.linalg.lstsq(X,y)[0]\n",
    "    num_relevant = d\n",
    "    biginds = np.where( abs(w) > tol)[0]\n",
    "    \n",
    "    # Threshold and continue\n",
    "    for j in range(maxit):\n",
    "\n",
    "        # Figure out which items to cut out\n",
    "        smallinds = np.where( abs(w) < tol)[0]\n",
    "        new_biginds = [i for i in range(d) if i not in smallinds]\n",
    "            \n",
    "        # If nothing changes then stop\n",
    "        if num_relevant == len(new_biginds): break\n",
    "        else: num_relevant = len(new_biginds)\n",
    "            \n",
    "        # Also make sure we didn't just lose all the coefficients\n",
    "        if len(new_biginds) == 0:\n",
    "            if j == 0: \n",
    "                #if print_results: print \"Tolerance too high - all coefficients set below tolerance\"\n",
    "                return w\n",
    "            else: break\n",
    "        biginds = new_biginds\n",
    "        \n",
    "        # Otherwise get a new guess\n",
    "        w[smallinds] = 0\n",
    "        if lam != 0: w[biginds] = np.linalg.lstsq(X[:, biginds].T.dot(X[:, biginds]) + lam*np.eye(len(biginds)),X[:, biginds].T.dot(y))[0]\n",
    "        else: w[biginds] = np.linalg.lstsq(X[:, biginds],y)[0]\n",
    "\n",
    "    # Now that we have the sparsity pattern, use standard least squares to get w\n",
    "    if biginds != []: w[biginds] = np.linalg.lstsq(X[:, biginds],y)[0]\n",
    "    \n",
    "    if normalize != 0: return np.multiply(Mreg,w)\n",
    "    else: return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9fe2e4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "M = 10 #m轮更新\n",
    "b = 1.2 #叛逃者的收益\n",
    "K = 0.1\n",
    "P_PDG = array([[1,0],[b,0]]) #2*2的收益矩阵\n",
    "Noise = 5\n",
    "W = np.loadtxt(\"karate.txt\") \n",
    "T = W.shape[0] #全部社区内个体的总数量\n",
    "SV = 6\n",
    "# the part for generate EG data\n",
    "y = zeros((SV*M,T))\n",
    "AA = zeros((T,SV*M,T))\n",
    "for i in range(SV): #产生6组A和Y的值\n",
    "    [A, Aa] = data_generate(M,P_PDG,W,T,K,Noise)\n",
    "    for j in range(M):\n",
    "        y[i*M+j,:] =Aa[j,:]\n",
    "        for k in range(T):\n",
    "            AA[k,i*M+j,:] = A[k,j,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf2aa481",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-13ac3e2d7f51>:30: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  w_best = np.linalg.lstsq(TrainR, TrainY)[0]\n",
      "<ipython-input-3-13ac3e2d7f51>:76: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  if lam != 0: w = np.linalg.lstsq(X.T.dot(X) + lam*np.eye(d),X.T.dot(y))[0]\n",
      "<ipython-input-3-13ac3e2d7f51>:102: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  if lam != 0: w[biginds] = np.linalg.lstsq(X[:, biginds].T.dot(X[:, biginds]) + lam*np.eye(len(biginds)),X[:, biginds].T.dot(y))[0]\n",
      "<ipython-input-3-13ac3e2d7f51>:106: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  if biginds != []: w[biginds] = np.linalg.lstsq(X[:, biginds],y)[0]\n",
      "<ipython-input-13-0ca45682905e>:5: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  X[i,j]=w[i,0]\n",
      "<ipython-input-3-13ac3e2d7f51>:106: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  if biginds != []: w[biginds] = np.linalg.lstsq(X[:, biginds],y)[0]\n"
     ]
    }
   ],
   "source": [
    "X=zeros((T,T))\n",
    "for j in range(T):\n",
    "    w = TrainSTRidge(AA[j], y[:,j].reshape(-1,1),10**-1,1)\n",
    "    for i in range(w.shape[0]):\n",
    "        X[i,j]=w[i,0]\n",
    "np.savetxt(\"X.txt\", X,fmt='%f',delimiter=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "40b38b8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.62070504e+00 7.48374336e-01 1.11160694e+00 1.93244491e+00\n",
      "  4.51299238e+00 2.24974995e+00 3.06531729e+00 4.51174292e+00\n",
      "  4.96401752e-01 4.84904534e+00 3.26570018e+00 8.54547926e-01\n",
      "  1.79076083e+00 3.75343071e+00 3.03915334e+00 1.62523615e+00\n",
      "  1.92127132e-01 3.17137029e+00 4.79474634e+00 3.26395159e+00\n",
      "  3.17529437e+00 4.97649784e+00 2.90925165e+00 2.07184294e+00\n",
      "  2.37348751e+00 3.11755051e+00 1.69003807e+00 3.37376161e+00\n",
      "  1.58600871e+00 3.89172741e+00 4.74785527e+00 3.31263433e+00\n",
      "  6.78581781e-02 3.11423048e+00]\n",
      " [3.36829815e+00 4.85972501e+00 4.39096736e+00 2.54812188e+00\n",
      "  2.78573469e-01 2.25579607e+00 9.99383270e-02 2.20855461e+00\n",
      "  4.89793364e+00 1.79722232e+00 2.40446765e+00 3.44330591e+00\n",
      "  4.40237945e+00 4.59117733e+00 1.08411069e+00 2.82594433e+00\n",
      "  4.32551281e+00 2.54484480e+00 4.58361477e+00 4.60578805e+00\n",
      "  4.15562463e-01 1.38859281e+00 4.67835243e-02 4.21171040e+00\n",
      "  3.23587070e+00 4.20693060e+00 1.32365082e+00 1.98910376e+00\n",
      "  2.76410740e+00 8.24702301e-01 1.84904046e+00 7.32208814e-01\n",
      "  2.84809203e+00 3.51868640e+00]\n",
      " [1.44238219e+00 2.16644031e+00 3.78053347e+00 1.98049138e+00\n",
      "  4.48019194e+00 3.19460538e+00 4.45777219e+00 3.40027785e+00\n",
      "  2.24598869e+00 4.89285464e+00 5.81009548e-01 3.83511852e+00\n",
      "  2.05910069e+00 3.37719541e+00 1.24898138e+00 1.56609166e+00\n",
      "  4.82708110e+00 2.94232543e+00 3.29834206e+00 2.66603127e+00\n",
      "  1.15266512e+00 1.97434647e+00 3.09404282e+00 2.37433758e+00\n",
      "  2.35066095e+00 3.58037266e+00 1.43995502e+00 1.91731113e+00\n",
      "  3.74584919e+00 4.39226095e+00 5.14316793e-01 4.61869447e-01\n",
      "  1.77023331e+00 2.75908130e+00]\n",
      " [1.68125467e-01 4.84480883e+00 1.60498621e+00 1.10631343e+00\n",
      "  7.06319525e-01 4.86299635e-01 4.92021121e+00 1.30170464e+00\n",
      "  2.68511261e+00 2.23963086e+00 4.97845446e-01 1.76155831e+00\n",
      "  2.34624587e+00 4.20570065e+00 4.52323872e+00 1.87796919e-01\n",
      "  2.54157724e+00 8.34237565e-01 3.89525510e+00 4.32466648e+00\n",
      "  2.05698362e+00 6.99862927e-01 1.66111926e-01 4.91287480e+00\n",
      "  1.86645375e+00 2.10037685e+00 2.52940575e-01 1.82748053e+00\n",
      "  8.31398687e-02 1.15371168e+00 3.82455849e+00 4.72061760e+00\n",
      "  3.74999624e+00 1.69701910e+00]\n",
      " [2.44774468e+00 1.69492558e+00 8.97451305e-01 8.54932993e-01\n",
      "  2.31725489e+00 4.37286479e+00 4.72059875e+00 3.04126433e+00\n",
      "  2.98327703e+00 3.91822123e+00 2.50013149e+00 2.51850284e-01\n",
      "  3.49549037e+00 4.96198199e+00 1.33631269e+00 3.39545308e+00\n",
      "  4.32140721e+00 3.75422123e+00 4.82244884e+00 2.77121218e+00\n",
      "  1.06195249e+00 1.11221612e+00 1.09374687e+00 2.84786767e+00\n",
      "  2.26054518e+00 4.85118342e+00 3.40272346e+00 4.26477829e-01\n",
      "  2.82091664e-01 2.43918852e+00 4.40502281e+00 4.88202193e+00\n",
      "  3.08828958e+00 2.71249388e+00]\n",
      " [4.27306790e+00 3.71917273e+00 2.39298163e+00 3.38540787e+00\n",
      "  3.03522531e+00 3.57348468e+00 2.34748592e+00 2.28007312e+00\n",
      "  4.53209044e+00 6.86102100e-01 1.14609662e+00 4.40792700e+00\n",
      "  4.52212488e+00 3.22892299e+00 1.62341486e+00 2.59855597e+00\n",
      "  2.76784325e-04 1.55930110e+00 2.12725769e+00 4.42668830e+00\n",
      "  3.39939728e+00 2.28064886e+00 2.41704308e+00 3.94369714e+00\n",
      "  1.14720917e+00 4.40148802e+00 1.56846196e+00 4.78725428e+00\n",
      "  2.35875785e+00 3.55791909e+00 7.68471525e-01 3.65221088e+00\n",
      "  3.23132219e+00 1.07440368e+00]\n",
      " [9.32291097e-01 4.03790134e+00 3.73539735e+00 3.37423673e+00\n",
      "  1.38446875e+00 8.74544372e-01 3.52237129e+00 2.31575100e+00\n",
      "  4.20214266e+00 1.02432881e+00 8.24794340e-01 6.24165287e-01\n",
      "  3.61040331e+00 1.52264825e-01 3.73497120e+00 4.62980826e-01\n",
      "  1.08725246e+00 3.74627209e+00 3.65846878e+00 2.28073186e-01\n",
      "  1.04578515e+00 1.43457522e+00 3.38631653e+00 3.15191448e-01\n",
      "  2.77824621e+00 4.62003674e-02 4.16519049e+00 4.92164717e+00\n",
      "  3.51747392e+00 9.08156002e-01 2.56196732e+00 2.90223569e+00\n",
      "  3.93771078e+00 3.03237730e+00]\n",
      " [1.09201427e+00 2.27584408e+00 4.39434871e+00 2.46134121e+00\n",
      "  3.57780579e+00 2.43079780e+00 3.54274075e+00 2.49070113e+00\n",
      "  4.22275040e+00 9.71711115e-01 3.86663005e+00 4.87129332e+00\n",
      "  4.31154889e+00 3.90213326e+00 4.92516139e+00 3.76784803e+00\n",
      "  2.02405318e-02 1.34739717e+00 2.05246069e+00 2.14111916e+00\n",
      "  1.48920909e+00 2.00566171e+00 6.03284956e-01 4.90349837e+00\n",
      "  2.03060246e+00 2.84605380e+00 1.71802752e+00 3.94436389e+00\n",
      "  2.05686207e+00 1.79635709e+00 1.99749455e+00 1.50915438e+00\n",
      "  3.87609889e+00 4.63106465e+00]\n",
      " [1.62655153e+00 4.76435336e+00 6.97419797e-02 2.66732841e+00\n",
      "  1.52291015e+00 4.41429999e+00 1.25311360e+00 3.38705915e+00\n",
      "  4.05212046e+00 2.16074025e+00 3.76067260e+00 4.14801124e+00\n",
      "  1.89516886e+00 4.82748049e-01 1.28069789e+00 2.95967579e+00\n",
      "  2.38238600e+00 2.43967284e+00 2.29257276e+00 2.62296310e+00\n",
      "  2.21007659e+00 4.26317462e+00 2.16719487e+00 4.13435184e+00\n",
      "  2.54671033e+00 4.31884902e-01 3.30019931e+00 1.03297304e+00\n",
      "  4.23637661e+00 3.40679565e+00 8.91836747e-01 3.49295087e-01\n",
      "  4.84408540e-02 4.46024829e+00]\n",
      " [6.67326048e-01 3.89595987e+00 4.62581713e+00 3.57589374e+00\n",
      "  2.45409306e+00 2.34749151e+00 4.41354645e+00 2.44205030e+00\n",
      "  2.07283743e+00 8.70559761e-01 2.37644721e+00 3.91823983e+00\n",
      "  2.78214714e+00 7.99335410e-01 7.19146828e-01 3.24731515e+00\n",
      "  2.69611799e+00 1.62842383e+00 7.35069474e-01 7.99350336e-01\n",
      "  6.47061687e-01 2.89461194e+00 4.61300852e-01 4.55272361e+00\n",
      "  4.14858738e-01 4.00189231e+00 4.38565483e+00 4.67297282e-01\n",
      "  2.13152940e+00 2.36610337e+00 2.90098553e+00 3.58122087e+00\n",
      "  1.35344924e-01 3.65698670e+00]]\n"
     ]
    }
   ],
   "source": [
    "print(Noise*random.random((M,T)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b210bd53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TrainSTRidge_SPL(R, Ut, v, lam, d_tol, maxit = 25, STR_iters = 10, l0_penalty = None, normalize = 2, split = 0.8, print_best_tol = False):\n",
    "    \"\"\"\n",
    "    This function trains a predictor using STRidge_SPL.\n",
    "\n",
    "    It runs over different values of tolerance and trains predictors on a training set, then evaluates them \n",
    "    using a loss function on a holdout set.\n",
    "\n",
    "    Please note published article has typo.  Loss function used here for model selection evaluates fidelity using 2-norm,\n",
    "    not squared 2-norm.\n",
    "    \"\"\"\n",
    "\n",
    "    # Split data into 80% training and 20% test, then search for the best tolderance.\n",
    "    np.random.seed(0) # for consistancy\n",
    "    n,_ = R.shape\n",
    "    train = np.random.choice(n, int(n*split), replace = False)\n",
    "    test = [i for i in np.arange(n) if i not in train]\n",
    "    TrainR = R[train,:]\n",
    "    TestR = R[test,:]\n",
    "    TrainY = Ut[train,:]\n",
    "    TestY = Ut[test,:]\n",
    "    D = TrainR.shape[1]       \n",
    "\n",
    "    # Set up the initial tolerance and l0 penalty\n",
    "    d_tol = float(d_tol)\n",
    "    tol = d_tol\n",
    "    if l0_penalty == None: l0_penalty = 0.001*np.linalg.cond(R)\n",
    "\n",
    "    # Get the standard least squares estimator\n",
    "    w = np.zeros((D,1))\n",
    "    w_best = np.linalg.lstsq(TrainR, TrainY)[0]\n",
    "    err_best = np.linalg.norm(TestY - TestR.dot(w_best), 2) + l0_penalty*np.count_nonzero(w_best)\n",
    "    tol_best = 0\n",
    "\n",
    "    # Now increase tolerance until test performance decreases\n",
    "    for iter in range(maxit):\n",
    "\n",
    "        # Get a set of coefficients and error\n",
    "        w = STRidge_SPL(R,Ut,v,lam,STR_iters,tol,normalize = normalize)\n",
    "        err = np.linalg.norm(TestY - TestR.dot(w), 2) + l0_penalty*np.count_nonzero(w)\n",
    "\n",
    "        # Has the accuracy improved?\n",
    "        if err <= err_best:\n",
    "            err_best = err\n",
    "            w_best = w\n",
    "            tol_best = tol\n",
    "            tol = tol + d_tol\n",
    "\n",
    "        else:\n",
    "            tol = max([0,tol - 2*d_tol])\n",
    "            d_tol  = 2*d_tol / (maxit - iter)\n",
    "            tol = tol + d_tol\n",
    "\n",
    "    if print_best_tol: \n",
    "        print (\"Optimal tolerance:\", tol_best)\n",
    "    return w_best\n",
    "\n",
    "def STRidge_SPL(X0, y, v, lam, maxit, tol, normalize = 2, print_results = False):\n",
    "    \"\"\"\n",
    "    Sequential Threshold Ridge Regression algorithm for finding (hopefully) sparse \n",
    "    approximation to X^{-1}y.  The idea is that this may do better with correlated observables.\n",
    "\n",
    "    This assumes y is only one column\n",
    "    \"\"\"\n",
    "\n",
    "    n,d = X0.shape\n",
    "    X = np.zeros((n,d), dtype=np.complex64)\n",
    "    # First normalize data\n",
    "    if normalize != 0:\n",
    "        Mreg = np.zeros((d,1))\n",
    "        for i in range(0,d):\n",
    "            Mreg[i] = 1.0/(np.linalg.norm(X0[:,i],normalize))\n",
    "            X[:,i] = Mreg[i]*X0[:,i]\n",
    "    else: X = X0\n",
    "    \n",
    "    # Get the standard ridge esitmate\n",
    "    if lam != 0: w = np.linalg.lstsq(X.T.dot(X*v) + lam*np.eye(d),X.T.dot(y*v))[0]\n",
    "    else: w = np.linalg.lstsq(X*v,y*v)[0]\n",
    "    num_relevant = d\n",
    "    biginds = np.where( abs(w) > tol)[0]\n",
    "    \n",
    "    # Threshold and continue\n",
    "    for j in range(maxit):\n",
    "\n",
    "        # Figure out which items to cut out\n",
    "        smallinds = np.where( abs(w) < tol)[0]\n",
    "        new_biginds = [i for i in range(d) if i not in smallinds]\n",
    "            \n",
    "        # If nothing changes then stop\n",
    "        if num_relevant == len(new_biginds): break\n",
    "        else: num_relevant = len(new_biginds)\n",
    "            \n",
    "        # Also make sure we didn't just lose all the coefficients\n",
    "        if len(new_biginds) == 0:\n",
    "            if j == 0: \n",
    "                #if print_results: print \"Tolerance too high - all coefficients set below tolerance\"\n",
    "                return w\n",
    "            else: break\n",
    "        biginds = new_biginds\n",
    "        \n",
    "        # Otherwise get a new guess\n",
    "        w[smallinds] = 0\n",
    "        if lam != 0: w[biginds] = np.linalg.lstsq(X[:, biginds].T.dot(X[:, biginds]*v) + lam*np.eye(len(biginds)),X[:, biginds].T.dot(y*v))[0]\n",
    "        else: w[biginds] = np.linalg.lstsq(X[:, biginds]*v,y*v)[0]\n",
    "\n",
    "    # Now that we have the sparsity pattern, use standard least squares to get w\n",
    "    if biginds != []: w[biginds] = np.linalg.lstsq(X[:, biginds]*v,y*v)[0]\n",
    "    \n",
    "    if normalize != 0: return np.multiply(Mreg,w)\n",
    "    else: return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c4d6f9bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-15-5e04d6e95ebc>:30: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  w_best = np.linalg.lstsq(TrainR, TrainY)[0]\n",
      "<ipython-input-15-5e04d6e95ebc>:76: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  if lam != 0: w = np.linalg.lstsq(X.T.dot(X*v) + lam*np.eye(d),X.T.dot(y*v))[0]\n",
      "<ipython-input-15-5e04d6e95ebc>:102: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  if lam != 0: w[biginds] = np.linalg.lstsq(X[:, biginds].T.dot(X[:, biginds]*v) + lam*np.eye(len(biginds)),X[:, biginds].T.dot(y*v))[0]\n",
      "<ipython-input-15-5e04d6e95ebc>:106: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  if biginds != []: w[biginds] = np.linalg.lstsq(X[:, biginds]*v,y*v)[0]\n",
      "<ipython-input-27-7122ccb68bd6>:18: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  X[i,j]=w[i,0]\n",
      "<ipython-input-15-5e04d6e95ebc>:106: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  if biginds != []: w[biginds] = np.linalg.lstsq(X[:, biginds]*v,y*v)[0]\n"
     ]
    }
   ],
   "source": [
    "X=zeros((T,T))\n",
    "v = ones((SV*M,1))\n",
    "v1 = zeros((SV*M,1))\n",
    "Los = zeros((SV*M,T))\n",
    "losss = zeros((SV*M,1))\n",
    "lambda_0=1.2\n",
    "t=0\n",
    "while (t<15):  \n",
    "    if (v==v1).all():\n",
    "        break\n",
    "    else:\n",
    "        for j in range(T):\n",
    "            w = TrainSTRidge_SPL(AA[j], y[:,j].reshape(-1,1), v,10**-1,1)\n",
    "            Lo =  abs((np.dot(AA[j], w))-y[:,j].reshape(-1,1))\n",
    "            for i in range(SV*M):\n",
    "                Los[i,j]=Lo[i]\n",
    "            for i in range(w.shape[0]):\n",
    "                X[i,j]=w[i,0]\n",
    "        for i in range(SV*M):\n",
    "            losss[i]=np.mean(Los[i,:])\n",
    "        t = t+1\n",
    "        for i in range(SV*M):\n",
    "            if losss[i]<lambda_0:\n",
    "                v[i]=1-losss[i]/lambda_0\n",
    "            else:\n",
    "                v[i]=0\n",
    "        lambda_0 = lambda_0*1.25\n",
    "        #lambda_0 = lambda_0 + np.mean(losss)      \n",
    "np.savetxt(\"X1.txt\", X,fmt='%f',delimiter=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ff62e5d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.97996669],\n",
       "       [0.95817346],\n",
       "       [0.96831368],\n",
       "       [0.97217506],\n",
       "       [0.94962041],\n",
       "       [0.96390412],\n",
       "       [0.96885454],\n",
       "       [0.95742909],\n",
       "       [0.96699506],\n",
       "       [0.96567024],\n",
       "       [0.96063059],\n",
       "       [0.96211304],\n",
       "       [0.95674557],\n",
       "       [0.96483252],\n",
       "       [0.94279095],\n",
       "       [0.95542842],\n",
       "       [0.96357834],\n",
       "       [0.96715813],\n",
       "       [0.94101903],\n",
       "       [0.94535195],\n",
       "       [0.95770201],\n",
       "       [0.96711754],\n",
       "       [0.96654373],\n",
       "       [0.97365981],\n",
       "       [0.9725164 ],\n",
       "       [0.96098005],\n",
       "       [0.96396715],\n",
       "       [0.96103735],\n",
       "       [0.95982516],\n",
       "       [0.95242361],\n",
       "       [0.95731246],\n",
       "       [0.96114433],\n",
       "       [0.96112842],\n",
       "       [0.91725331],\n",
       "       [0.90917586],\n",
       "       [0.89906616],\n",
       "       [0.91447702],\n",
       "       [0.91648031],\n",
       "       [0.90192161],\n",
       "       [0.90109187],\n",
       "       [0.96469513],\n",
       "       [0.97262274],\n",
       "       [0.95436166],\n",
       "       [0.93721209],\n",
       "       [0.96745792],\n",
       "       [0.96578812],\n",
       "       [0.96501491],\n",
       "       [0.96286838],\n",
       "       [0.96235767],\n",
       "       [0.95424062],\n",
       "       [0.96747588],\n",
       "       [0.96118151],\n",
       "       [0.95154276],\n",
       "       [0.9678224 ],\n",
       "       [0.96004218],\n",
       "       [0.94166158],\n",
       "       [0.92099977],\n",
       "       [0.88858318],\n",
       "       [0.91456411],\n",
       "       [0.92406047]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e00da151",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-15-5e04d6e95ebc>:30: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  w_best = np.linalg.lstsq(TrainR, TrainY)[0]\n",
      "<ipython-input-15-5e04d6e95ebc>:76: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  if lam != 0: w = np.linalg.lstsq(X.T.dot(X*v) + lam*np.eye(d),X.T.dot(y*v))[0]\n",
      "<ipython-input-15-5e04d6e95ebc>:102: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  if lam != 0: w[biginds] = np.linalg.lstsq(X[:, biginds].T.dot(X[:, biginds]*v) + lam*np.eye(len(biginds)),X[:, biginds].T.dot(y*v))[0]\n",
      "<ipython-input-15-5e04d6e95ebc>:106: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  if biginds != []: w[biginds] = np.linalg.lstsq(X[:, biginds]*v,y*v)[0]\n",
      "<ipython-input-38-864c51c54bde>:17: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  X[i,j]=w[i,0]\n",
      "<ipython-input-15-5e04d6e95ebc>:106: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  if biginds != []: w[biginds] = np.linalg.lstsq(X[:, biginds]*v,y*v)[0]\n"
     ]
    }
   ],
   "source": [
    "X=zeros((T,T))\n",
    "v = ones((SV*M,T))\n",
    "v1 = zeros((SV*M,T))\n",
    "Los = zeros((SV*M,T))\n",
    "lambda_0=1\n",
    "t=0\n",
    "while (t<26):\n",
    "    if (v==v1).all():\n",
    "        break\n",
    "    else:\n",
    "        for j in range(T):\n",
    "            w = TrainSTRidge_SPL(AA[j], y[:,j].reshape(-1,1), v[:,j].reshape(-1,1),10**-1,1)\n",
    "            Lo =  abs((np.dot(AA[j], w))-y[:,j].reshape(-1,1))\n",
    "            for i in range(SV*M):\n",
    "                Los[i,j]=Lo[i]\n",
    "            for i in range(w.shape[0]):\n",
    "                X[i,j]=w[i,0]\n",
    "        t = t+1\n",
    "        for j in range(T):\n",
    "            for i in range(SV*M):\n",
    "                if Los[i,j]<lambda_0:\n",
    "                    v[i,j]=1-Los[i,j]/lambda_0\n",
    "                else:\n",
    "                    v[i,j]=0\n",
    "        #lambda_0 = lambda_0*1.05\n",
    "        lambda_0 = lambda_0 + np.mean(Los)\n",
    "np.savetxt(\"X2.txt\", X,fmt='%f',delimiter=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "15d2e7c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.37870097, 0.66250314, 0.63539229, ..., 0.70497306, 0.42023463,\n",
       "        0.72644436],\n",
       "       [0.44197853, 0.02274707, 0.34194074, ..., 1.66995031, 0.09649499,\n",
       "        2.6694491 ],\n",
       "       [1.22916629, 0.60765015, 0.13928353, ..., 1.23542402, 1.70646646,\n",
       "        0.25479451],\n",
       "       ...,\n",
       "       [3.7666106 , 3.60093495, 2.69736165, ..., 4.52428426, 1.75664205,\n",
       "        3.71130563],\n",
       "       [1.31148484, 0.53551114, 4.72996811, ..., 1.44722885, 0.20281881,\n",
       "        3.67498732],\n",
       "       [0.15090862, 0.1932285 , 0.79133629, ..., 0.62168167, 4.10645821,\n",
       "        2.78130047]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18984880",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
